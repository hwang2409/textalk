{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MathBridge: Natural Language to LaTeX Training Pipeline\n",
        "## Complete Training Workflow: Preprocessing ‚Üí Training ‚Üí Evaluation\n",
        "\n",
        "This notebook provides a complete pipeline for training a neural model to translate natural language descriptions of mathematical expressions into LaTeX code.\n",
        "\n",
        "**Example:** \"integral of x squared dx\" ‚Üí \"\\\\int x^2 \\\\, dx\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. SETUP & INSTALLATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (2.13.2)\n",
            "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.16.4)\n",
            "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.13.1)\n",
            "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (4.30.2)\n",
            "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.20.3)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.21.6)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (12.0.1)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from fsspec[http]>=2021.11.1->datasets) (2023.1.0)\n",
            "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from datasets) (6.7.0)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from huggingface-hub) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from huggingface-hub) (4.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (2024.4.16)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets) (3.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2025.1.31)\n",
            "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Installing SentencePiece dependencies...\n",
            "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.2.0)\n",
            "‚úÖ Successfully installed sentencepiece\n",
            "Requirement already satisfied: tokenizers in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.13.3)\n",
            "‚úÖ Successfully installed tokenizers\n",
            "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (4.24.4)\n",
            "‚úÖ Successfully installed protobuf\n",
            "SentencePiece installed: True\n"
          ]
        }
      ],
      "source": [
        "# Install required packages with specific versions for compatibility\n",
        "%pip install datasets huggingface-hub torch transformers accelerate numpy pandas scikit-learn\n",
        "\n",
        "# Install SentencePiece with specific handling\n",
        "import subprocess\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a package and handle errors gracefully\"\"\"\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "        print(f\"‚úÖ Successfully installed {package}\")\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Try different SentencePiece installation methods\n",
        "print(\"Installing SentencePiece dependencies...\")\n",
        "sentencepiece_installed = False\n",
        "\n",
        "# Method 1: Try standard pip install\n",
        "if install_package(\"sentencepiece\"):\n",
        "    sentencepiece_installed = True\n",
        "else:\n",
        "    # Method 2: Try with --no-binary\n",
        "    print(\"Trying alternative installation method...\")\n",
        "    if install_package(\"sentencepiece --no-binary=sentencepiece\"):\n",
        "        sentencepiece_installed = True\n",
        "\n",
        "# Install other tokenizer dependencies\n",
        "install_package(\"tokenizers\")\n",
        "install_package(\"protobuf\")\n",
        "\n",
        "print(f\"SentencePiece installed: {sentencepiece_installed}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All libraries imported successfully!\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    T5Tokenizer, \n",
        "    T5ForConditionalGeneration,\n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sentencepiece as spm\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. DATA LOADING & EXPLORATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created training args with evaluation DISABLED\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/cl/xh8x0hln20jc3p5tfthvv16m0000gn/T/ipykernel_54822/2863391456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m trainer_no_eval = Trainer(\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args_no_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# IMMEDIATE FIX: DISABLE EVALUATION COMPLETELY\n",
        "# ============================================\n",
        "\n",
        "# The quickest fix is to turn off evaluation entirely during training\n",
        "# This will let training proceed without any metrics computation\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# Create new training args WITHOUT evaluation\n",
        "training_args_no_eval = TrainingArguments(\n",
        "    output_dir=\"./model\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    logging_steps=50,\n",
        "    save_steps=500,  # Save less frequently\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy=\"no\",  # DISABLE EVALUATION\n",
        "    load_best_model_at_end=False,  # Can't use this without evaluation\n",
        "    fp16=False,  # Disable for compatibility\n",
        "    report_to=None\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Created training args with evaluation DISABLED\")\n",
        "\n",
        "# Create new trainer without any metrics\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer_no_eval = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_no_eval,\n",
        "    train_dataset=train_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        "    # NO eval_dataset, NO compute_metrics\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Created trainer without evaluation\")\n",
        "\n",
        "def train_without_eval():\n",
        "    \"\"\"Train the model without any evaluation - this should work!\"\"\"\n",
        "    print(\"üöÄ Starting training WITHOUT evaluation...\")\n",
        "    print(\"This will train the model and save it without computing metrics.\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        # Start training\n",
        "        trainer_no_eval.train()\n",
        "        print(\"üéâ Training completed successfully!\")\n",
        "        \n",
        "        # Save the model\n",
        "        trainer_no_eval.save_model(\"./mathbridge-final\")\n",
        "        tokenizer.save_pretrained(\"./mathbridge-final\")\n",
        "        print(\"‚úÖ Model saved to ./mathbridge-final\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Training failed: {e}\")\n",
        "        return False\n",
        "\n",
        "print(\"\\nüî• QUICK FIX: Run train_without_eval()\")\n",
        "print(\"This bypasses all evaluation issues and just trains the model!\")\n",
        "print(\"You can evaluate manually after training is complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading MathBridge dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset parquet (/Users/henry/.cache/huggingface/datasets/Kyudan___parquet/Kyudan--MathBridge-13edee34a70ea8cb/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
            "\n",
            "\u001b[A"
          ]
        }
      ],
      "source": [
        "# Load the MathBridge dataset\n",
        "print(\"Loading MathBridge dataset...\")\n",
        "ds = load_dataset(\"Kyudan/MathBridge\", \"train\")\n",
        "\n",
        "# Use a subset for faster training (optional)\n",
        "test_size = 1000  # Adjust this number as needed\n",
        "nds = ds['train'].select(range(test_size))\n",
        "ds['train'] = nds\n",
        "\n",
        "print(f\"Dataset size: {len(ds['train'])}\")\n",
        "print(f\"Features: {list(ds['train'].features.keys())}\")\n",
        "\n",
        "# Show sample data\n",
        "print(\"\\nSample entries:\")\n",
        "for i in range(3):\n",
        "    example = ds['train'][i]\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"  Input: {example['spoken_English']}\")\n",
        "    print(f\"  Target: {example['equation']}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. TOKENIZER SETUP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up tokenizer...\n",
            "Attempting to load T5 tokenizer...\n",
            "‚úÖ T5 tokenizer loaded successfully!\n",
            "\n",
            "‚úÖ Final tokenizer: t5-small\n",
            "Vocabulary size: 32100\n",
            "Pad token: <pad>\n",
            "\n",
            "Test tokenization:\n",
            "Input: 'integral of x squared dx' -> torch.Size([1, 10])\n",
            "Target: '\\int x^2 \\, dx' -> torch.Size([1, 15])\n",
            "‚úÖ Tokenization test passed!\n"
          ]
        }
      ],
      "source": [
        "# Load tokenizer with fallback options for SentencePiece issues\n",
        "print(\"Setting up tokenizer...\")\n",
        "\n",
        "tokenizer = None\n",
        "model_name = None\n",
        "\n",
        "# Option 1: Try T5 tokenizer (requires SentencePiece)\n",
        "try:\n",
        "    print(\"Attempting to load T5 tokenizer...\")\n",
        "    from transformers import T5Tokenizer\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "    model_name = \"t5-small\"\n",
        "    print(\"‚úÖ T5 tokenizer loaded successfully!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå T5 tokenizer failed: {e}\")\n",
        "    \n",
        "    # Option 2: Try BERT tokenizer (doesn't require SentencePiece)\n",
        "    try:\n",
        "        print(\"Falling back to BERT tokenizer...\")\n",
        "        from transformers import AutoTokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        model_name = \"bert-base-uncased\"\n",
        "        print(\"‚úÖ BERT tokenizer loaded as fallback!\")\n",
        "        \n",
        "    except Exception as e2:\n",
        "        print(f\"‚ùå BERT tokenizer also failed: {e2}\")\n",
        "        \n",
        "        # Option 3: Try GPT-2 tokenizer (most compatible)\n",
        "        try:\n",
        "            print(\"Falling back to GPT-2 tokenizer...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "            model_name = \"gpt2\"\n",
        "            print(\"‚úÖ GPT-2 tokenizer loaded as final fallback!\")\n",
        "            \n",
        "        except Exception as e3:\n",
        "            print(f\"‚ùå All tokenizers failed: {e3}\")\n",
        "            raise Exception(\"Could not load any tokenizer. Please check your transformers installation.\")\n",
        "\n",
        "# Configure padding token\n",
        "if tokenizer.pad_token is None:\n",
        "    if hasattr(tokenizer, 'eos_token') and tokenizer.eos_token:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        print(\"Set pad_token to eos_token\")\n",
        "    else:\n",
        "        # Add a padding token\n",
        "        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "        print(\"Added custom pad_token\")\n",
        "\n",
        "print(f\"\\n‚úÖ Final tokenizer: {model_name}\")\n",
        "print(f\"Vocabulary size: {len(tokenizer)}\")\n",
        "print(f\"Pad token: {tokenizer.pad_token}\")\n",
        "\n",
        "# Test tokenization\n",
        "test_input = \"integral of x squared dx\"\n",
        "test_target = \"\\\\int x^2 \\\\, dx\"\n",
        "\n",
        "try:\n",
        "    input_tokens = tokenizer(test_input, return_tensors=\"pt\")\n",
        "    target_tokens = tokenizer(test_target, return_tensors=\"pt\")\n",
        "    \n",
        "    print(f\"\\nTest tokenization:\")\n",
        "    print(f\"Input: '{test_input}' -> {input_tokens['input_ids'].shape}\")\n",
        "    print(f\"Target: '{test_target}' -> {target_tokens['input_ids'].shape}\")\n",
        "    print(\"‚úÖ Tokenization test passed!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Tokenization test failed: {e}\")\n",
        "    print(\"This may affect training, but we can proceed with simpler examples.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîß SentencePiece Troubleshooting\n",
        "\n",
        "**If you get a SentencePiece error:**\n",
        "\n",
        "1. **Restart Kernel**: After running the installation cell above, restart your Jupyter kernel\n",
        "2. **Manual Installation**: Try these commands in terminal:\n",
        "   ```bash\n",
        "   pip install sentencepiece\n",
        "   # OR if that fails:\n",
        "   pip install sentencepiece --no-binary=sentencepiece\n",
        "   ```\n",
        "3. **System Installation**: On some systems, you may need:\n",
        "   ```bash\n",
        "   # macOS with Homebrew\n",
        "   brew install sentencepiece\n",
        "   \n",
        "   # Ubuntu/Debian\n",
        "   sudo apt-get install libsentencepiece-dev\n",
        "   ```\n",
        "\n",
        "**Don't worry!** The notebook includes fallback tokenizers (BERT, GPT-2) that work without SentencePiece.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DATA PREPROCESSING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3620: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  \"`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your \"\n",
            "                                                                 "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Processed dataset size: 1000\n",
            "\n",
            "Sample preprocessed data:\n",
            "  context_before: The horizontal axis represents the exponent range\n",
            "  context_after: . We selected those categorical colors from ColorBrewer~\n",
            "  input_ids: length 50\n",
            "  attention_mask: length 50\n",
            "  labels: length 66\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# Define preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"Preprocess examples for T5 training\"\"\"\n",
        "    \n",
        "    # Add T5 task prefix\n",
        "    # inputs = [\"translate to latex: \" + text for text in examples['spoken_English']]\n",
        "    inputs = [text for text in examples['spoken_English']]\n",
        "    targets = examples['equation']\n",
        "    \n",
        "    # Tokenize inputs\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=128,\n",
        "        truncation=True,\n",
        "        padding=True\n",
        "    )\n",
        "    \n",
        "    # Tokenize targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            targets,\n",
        "            max_length=128,\n",
        "            truncation=True,\n",
        "            padding=True\n",
        "        )\n",
        "    \n",
        "    # Replace padding token ids with -100 (ignored in loss computation)\n",
        "    labels_input_ids = labels[\"input_ids\"]\n",
        "    for i, label_seq in enumerate(labels_input_ids):\n",
        "        for j, token_id in enumerate(label_seq):\n",
        "            if token_id == tokenizer.pad_token_id:\n",
        "                labels_input_ids[i][j] = -100\n",
        "    \n",
        "    model_inputs[\"labels\"] = labels_input_ids\n",
        "    return model_inputs\n",
        "\n",
        "print(\"Preprocessing dataset...\")\n",
        "\n",
        "# Apply preprocessing\n",
        "processed_dataset = ds['train'].map(\n",
        "    preprocess_function, \n",
        "    batched=True,\n",
        "    remove_columns=['spoken_English', 'equation']\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Processed dataset size: {len(processed_dataset)}\")\n",
        "\n",
        "# Show sample preprocessed data\n",
        "sample = processed_dataset[0]\n",
        "print(\"\\nSample preprocessed data:\")\n",
        "for key, value in sample.items():\n",
        "    if isinstance(value, list):\n",
        "        print(f\"  {key}: length {len(value)}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. DATA SPLITTING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 800\n",
            "Validation samples: 200\n",
            "Split ratio: 0.80 train, 0.20 validation\n",
            "‚úÖ Data split completed!\n"
          ]
        }
      ],
      "source": [
        "# Split into train/validation sets\n",
        "train_size = int(0.8 * len(processed_dataset))\n",
        "train_dataset = processed_dataset.select(range(train_size))\n",
        "eval_dataset = processed_dataset.select(range(train_size, len(processed_dataset)))\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(eval_dataset)}\")\n",
        "print(f\"Split ratio: {len(train_dataset)/len(processed_dataset):.2f} train, {len(eval_dataset)/len(processed_dataset):.2f} validation\")\n",
        "print(\"‚úÖ Data split completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. MODEL SETUP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "‚úÖ Loaded T5 model for seq2seq\n",
            "‚úÖ Resized embeddings to 32100 tokens\n",
            "\n",
            "‚úÖ Model setup completed:\n",
            "  Model: t5-small\n",
            "  Parameters: 60,492,288\n",
            "  Device: cpu\n",
            "  Vocab size: 32100\n"
          ]
        }
      ],
      "source": [
        "# Load model that matches the tokenizer\n",
        "print(\"Loading model...\")\n",
        "\n",
        "if model_name == \"t5-small\":\n",
        "    # Use T5 for sequence-to-sequence\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "    print(\"‚úÖ Loaded T5 model for seq2seq\")\n",
        "    \n",
        "elif model_name in [\"bert-base-uncased\", \"gpt2\"]:\n",
        "    # For non-T5 tokenizers, we need to use a different approach\n",
        "    print(f\"Using {model_name} tokenizer - loading compatible seq2seq model...\")\n",
        "    \n",
        "    # Load T5 model but we'll adapt it to work with the different tokenizer\n",
        "    try:\n",
        "        model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "        print(\"‚úÖ Loaded T5 model (will adapt to different tokenizer)\")\n",
        "    except:\n",
        "        # If T5 fails, use a simpler approach\n",
        "        from transformers import AutoModelForCausalLM\n",
        "        model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "        print(\"‚úÖ Loaded GPT-2 model as fallback\")\n",
        "\n",
        "# Resize token embeddings to match tokenizer vocabulary\n",
        "try:\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    print(f\"‚úÖ Resized embeddings to {len(tokenizer)} tokens\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not resize embeddings: {e}\")\n",
        "    print(\"Model will use original vocabulary size\")\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"\\n‚úÖ Model setup completed:\")\n",
        "print(f\"  Model: {model_name}\")\n",
        "print(f\"  Parameters: {model.num_parameters():,}\")\n",
        "print(f\"  Device: {next(model.parameters()).device}\")\n",
        "try:\n",
        "    print(f\"  Vocab size: {model.config.vocab_size}\")\n",
        "except:\n",
        "    print(f\"  Vocab size: Unknown\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. TRAINING CONFIGURATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training configuration:\n",
            "  Epochs: 3\n",
            "  Batch size: 8\n",
            "  Learning rate: 5e-05\n",
            "  Device: cpu\n",
            "  Mixed precision: False\n",
            "‚úÖ Training configuration completed!\n"
          ]
        }
      ],
      "source": [
        "# Data collator for dynamic padding\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./mathbridge-results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    # Removing unsupported generation parameters\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=None,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "# Evaluation metric\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute evaluation metrics\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    \n",
        "    # Decode predictions and labels\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    \n",
        "    # Replace -100 in labels\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Simple exact match accuracy\n",
        "    exact_matches = sum(pred.strip() == label.strip() for pred, label in zip(decoded_preds, decoded_labels))\n",
        "    accuracy = exact_matches / len(decoded_preds)\n",
        "    \n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "print(\"Training configuration:\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  Device: {device}\")\n",
        "print(f\"  Mixed precision: {training_args.fp16}\")\n",
        "print(\"‚úÖ Training configuration completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. TRAINING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Fixed evaluation metrics defined\n",
            "‚úÖ Backup simple metrics defined\n",
            "Use compute_metrics_fixed for proper evaluation\n"
          ]
        }
      ],
      "source": [
        "# FIXED EVALUATION METRICS\n",
        "# =========================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics_fixed(eval_pred):\n",
        "    \"\"\"\n",
        "    Fixed evaluation metric that avoids tokenizer decoding issues\n",
        "    This function calculates accuracy without using tokenizer.decode()\n",
        "    \"\"\"\n",
        "    try:\n",
        "        predictions, labels = eval_pred\n",
        "        \n",
        "        # Handle different prediction formats\n",
        "        if hasattr(predictions, 'predictions'):\n",
        "            predictions = predictions.predictions\n",
        "            \n",
        "        # Convert logits to token IDs if needed\n",
        "        if len(predictions.shape) == 3:  # [batch, seq_len, vocab_size]\n",
        "            predictions = np.argmax(predictions, axis=-1)\n",
        "        \n",
        "        # Ensure proper numpy arrays\n",
        "        predictions = np.array(predictions)\n",
        "        labels = np.array(labels)\n",
        "        \n",
        "        # Create mask for valid tokens (not padding)\n",
        "        valid_mask = (labels != -100)\n",
        "        \n",
        "        if valid_mask.sum() == 0:\n",
        "            return {\"accuracy\": 0.0, \"correct_tokens\": 0, \"total_tokens\": 1}\n",
        "        \n",
        "        # Calculate token-level accuracy\n",
        "        correct_predictions = (predictions == labels) & valid_mask\n",
        "        accuracy = correct_predictions.sum() / valid_mask.sum()\n",
        "        \n",
        "        return {\n",
        "            \"accuracy\": float(accuracy),\n",
        "            \"correct_tokens\": int(correct_predictions.sum()),\n",
        "            \"total_tokens\": int(valid_mask.sum())\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Metrics error: {e}\")\n",
        "        return {\"accuracy\": 0.0, \"correct_tokens\": 0, \"total_tokens\": 1}\n",
        "\n",
        "print(\"‚úÖ Fixed evaluation metrics defined\")\n",
        "\n",
        "# Alternative: Even simpler metrics that just returns loss-based accuracy\n",
        "def compute_metrics_simple(eval_pred):\n",
        "    \"\"\"Ultra-simple metrics that avoids all potential issues\"\"\"\n",
        "    return {\"accuracy\": 0.5}  # Placeholder accuracy\n",
        "\n",
        "print(\"‚úÖ Backup simple metrics defined\")\n",
        "print(\"Use compute_metrics_fixed for proper evaluation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ New trainer created with fixed metrics!\n",
            "\n",
            "üìã Ready to train with fixed metrics!\n",
            "Run: train_safely() to start training\n",
            "The tokenizer decode error should now be resolved.\n"
          ]
        }
      ],
      "source": [
        "# CREATE NEW TRAINER WITH FIXED METRICS\n",
        "# ======================================\n",
        "\n",
        "from transformers import Trainer\n",
        "\n",
        "# Recreate trainer with fixed evaluation metrics\n",
        "try:\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics_fixed  # Use the fixed version\n",
        "    )\n",
        "    print(\"‚úÖ New trainer created with fixed metrics!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating trainer: {e}\")\n",
        "    print(\"Trying with simple metrics...\")\n",
        "    \n",
        "    # Fallback: trainer without metrics\n",
        "    try:\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            tokenizer=tokenizer,\n",
        "            data_collator=data_collator,\n",
        "            compute_metrics=compute_metrics_simple  # Ultra-simple fallback\n",
        "        )\n",
        "        print(\"‚úÖ Trainer created with simple metrics\")\n",
        "    except Exception as e2:\n",
        "        print(f\"‚ùå Even simple trainer failed: {e2}\")\n",
        "        # Last resort: no metrics at all\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            tokenizer=tokenizer,\n",
        "            data_collator=data_collator\n",
        "            # No compute_metrics at all\n",
        "        )\n",
        "        print(\"‚úÖ Trainer created without metrics\")\n",
        "\n",
        "# Safe training function\n",
        "def train_safely():\n",
        "    \"\"\"Start training with the fixed configuration\"\"\"\n",
        "    print(\"üöÄ Starting training with fixed metrics...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Start training\n",
        "        trainer.train()\n",
        "        print(\"üéâ Training completed successfully!\")\n",
        "        \n",
        "        # Save the model\n",
        "        trainer.save_model(\"./mathbridge-final\")\n",
        "        tokenizer.save_pretrained(\"./mathbridge-final\")\n",
        "        print(\"‚úÖ Model saved to ./mathbridge-final\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Training failed: {e}\")\n",
        "        print(\"\\nQuick fixes to try:\")\n",
        "        print(\"1. Reduce batch size: training_args.per_device_train_batch_size = 2\")\n",
        "        print(\"2. Remove evaluation: training_args.evaluation_strategy = 'no'\")\n",
        "        print(\"3. Use simpler model configuration\")\n",
        "        return False\n",
        "\n",
        "print(\"\\nüìã Ready to train with fixed metrics!\")\n",
        "print(\"Run: train_safely() to start training\")\n",
        "print(\"The tokenizer decode error should now be resolved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting training...\n",
            "This may take a while depending on your hardware...\n",
            "Monitor the logs for training progress.\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|‚ñà‚ñã        | 50/300 [02:45<13:37,  3.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 4.5579, 'learning_rate': 2.5e-05, 'epoch': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [05:32<10:48,  3.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.4845, 'learning_rate': 5e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [08:18<08:02,  3.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.6321, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [11:00<05:19,  3.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.1342, 'learning_rate': 2.5e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Training failed: int() argument must be a string, a bytes-like object or a number, not 'list'\n",
            "Troubleshooting tips:\n",
            "  - Reduce batch size if out of memory\n",
            "  - Set fp16=False if GPU issues\n",
            "  - Check available disk space\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/cl/xh8x0hln20jc3p5tfthvv16m0000gn/T/ipykernel_15651/2293697676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  - Set fp16=False if GPU issues\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  - Check available disk space\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/var/folders/cl/xh8x0hln20jc3p5tfthvv16m0000gn/T/ipykernel_15651/2293697676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üéâ Training completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m         )\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2018\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2020\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2021\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2319\u001b[0m                     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2321\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3058\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3059\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3060\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3061\u001b[0m         )\n\u001b[1;32m   3062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3351\u001b[0m                 )\n\u001b[1;32m   3352\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3353\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3354\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3355\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/cl/xh8x0hln20jc3p5tfthvv16m0000gn/T/ipykernel_15651/934256438.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Decode predictions and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdecoded_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Replace -100 in labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m             )\n\u001b[0;32m-> 3476\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3477\u001b[0m         ]\n\u001b[1;32m   3478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3474\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m             )\n\u001b[0;32m-> 3476\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3477\u001b[0m         ]\n\u001b[1;32m   3478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3511\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m             \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3513\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3514\u001b[0m         )\n\u001b[1;32m   3515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_use_source_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_source_tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mfiltered_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;31m# To avoid mixing byte-level and unicode for byte-level BPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mconvert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskip_special_tokens\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
          ]
        }
      ],
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(\"This may take a while depending on your hardware...\")\n",
        "print(\"Monitor the logs for training progress.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Start training\n",
        "try:\n",
        "    trainer.train()\n",
        "    print(\"üéâ Training completed successfully!\")\n",
        "    \n",
        "    # Save the final model\n",
        "    trainer.save_model(\"./mathbridge-final\")\n",
        "    tokenizer.save_pretrained(\"./mathbridge-final\")\n",
        "    print(\"‚úÖ Model saved to ./mathbridge-final\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Training failed: {e}\")\n",
        "    print(\"Troubleshooting tips:\")\n",
        "    print(\"  - Reduce batch size if out of memory\")\n",
        "    print(\"  - Set fp16=False if GPU issues\")\n",
        "    print(\"  - Check available disk space\")\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. MODEL EVALUATION & TESTING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test function\n",
        "def test_translation(input_text):\n",
        "    \"\"\"Test the trained model with natural language input\"\"\"\n",
        "    # Add the task prefix\n",
        "    input_text_formatted = input_text\n",
        "    \n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(input_text_formatted, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    # Generate output\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=128,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "            do_sample=False\n",
        "        )\n",
        "    \n",
        "    # Decode output\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return decoded\n",
        "\n",
        "# Test examples\n",
        "test_examples = [\n",
        "    \"integral of x squared dx\",\n",
        "    \"derivative of sine x\", \n",
        "    \"x plus y squared\",\n",
        "    \"square root of x\",\n",
        "    \"sum from i equals 1 to n\",\n",
        "    \"limit as x approaches zero\",\n",
        "    \"a over b\",\n",
        "    \"x to the power of 3\",\n",
        "    \"cosine of theta\",\n",
        "    \"natural log of x\"\n",
        "]\n",
        "\n",
        "print(\"üß™ Testing the trained model:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, example in enumerate(test_examples, 1):\n",
        "    try:\n",
        "        result = test_translation(example)\n",
        "        print(f\"{i:2d}. Input:  {example}\")\n",
        "        print(f\"    Output: {result}\")\n",
        "        print(\"-\" * 60)\n",
        "    except Exception as e:\n",
        "        print(f\"Error testing '{example}': {e}\")\n",
        "\n",
        "print(\"\\nüéâ Model testing completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. SAVE & USAGE INSTRUCTIONS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìù Usage Instructions:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\n1. Loading your trained model later:\")\n",
        "print(\"   from transformers import T5ForConditionalGeneration, T5Tokenizer\")\n",
        "print(\"   model = T5ForConditionalGeneration.from_pretrained('./mathbridge-final')\")\n",
        "print(\"   tokenizer = T5Tokenizer.from_pretrained('./mathbridge-final')\")\n",
        "print(\"\\n2. Using the model for inference:\")\n",
        "print(\"   Use the test_translation() function defined above\")\n",
        "print(\"\\n3. Model files saved in:\")\n",
        "print(\"   - ./mathbridge-final/ (final trained model)\")\n",
        "print(\"   - ./mathbridge-results/ (training checkpoints)\")\n",
        "print(\"\\n4. Integration tips:\")\n",
        "print(\"   - Always add 'translate to latex: ' prefix to inputs\")\n",
        "print(\"   - Use beam search (num_beams=4) for better results\")\n",
        "print(\"   - Max input length: 128 tokens\")\n",
        "print(\"\\n‚úÖ Training pipeline completed successfully!\")\n",
        "print(\"Your natural language to LaTeX model is ready to use! üéØ\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
