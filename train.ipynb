{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60917b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (2.13.2)\n",
      "Requirement already satisfied: huggingface-hub in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (0.16.4)\n",
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: pandas in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: multiprocess in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (6.7.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: packaging in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: filelock in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from huggingface-hub) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from huggingface-hub) (4.7.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2024.4.16-cp37-cp37m-macosx_10_9_x86_64.whl (297 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp37-cp37m-macosx_10_11_x86_64.whl (4.0 MB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.5.3.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from accelerate) (7.0.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Using cached torch-1.13.1-cp37-none-macosx_10_9_x86_64.whl (135.3 MB)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from aiohttp->datasets) (3.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0; python_version < \"3.8\" in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.17.0)\n",
      "Using legacy setup.py install for pytorch, since package 'wheel' is not installed.\n",
      "Building wheels for collected packages: safetensors\n",
      "  Building wheel for safetensors (PEP 517) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/henry/me/proj/hang/venv/bin/python /Users/henry/me/proj/hang/venv/lib/python3.7/site-packages/pip/_vendor/pep517/_in_process.py build_wheel /var/folders/cl/xh8x0hln20jc3p5tfthvv16m0000gn/T/tmpogajaq34\n",
      "       cwd: /private/var/folders/cl/xh8x0hln20jc3p5tfthvv16m0000gn/T/pip-install-jm98ud8f/safetensors\n",
      "  Complete output (12 lines):\n",
      "  Running `maturin pep517 build-wheel -i /Users/henry/me/proj/hang/venv/bin/python --compatibility off`\n",
      "      Blocking waiting for file lock on package cache\n",
      "  üçπ Building a mixed python/rust project\n",
      "  üîó Found pyo3 bindings with abi3 support\n",
      "  üêç Not using a specific python interpreter\n",
      "  üì° Using build options features, bindings from pyproject.toml\n",
      "  üíª Using `MACOSX_DEPLOYMENT_TARGET=10.7` for x86_64-apple-darwin by default\n",
      "  error: package `safetensors v0.5.3 (/private/var/folders/cl/xh8x0hln20jc3p5tfthvv16m0000gn/T/pip-install-jm98ud8f/safetensors/safetensors)` cannot be built because it requires rustc 1.74 or newer, while the currently active rustc version is 1.64.0\n",
      "  üí• maturin failed\n",
      "    Caused by: Failed to build a native library through cargo\n",
      "    Caused by: Cargo build finished with \"exit status: 101\": `env -u CARGO MACOSX_DEPLOYMENT_TARGET=\"10.7\" PYO3_BUILD_EXTENSION_MODULE=\"1\" PYO3_ENVIRONMENT_SIGNATURE=\"cpython-3.7-64bit\" PYO3_PYTHON=\"/Users/henry/me/proj/hang/venv/bin/python\" PYTHON_SYS_EXECUTABLE=\"/Users/henry/me/proj/hang/venv/bin/python\" \"cargo\" \"rustc\" \"--features\" \"pyo3/extension-module\" \"--message-format\" \"json-render-diagnostics\" \"--manifest-path\" \"/private/var/folders/cl/xh8x0hln20jc3p5tfthvv16m0000gn/T/pip-install-jm98ud8f/safetensors/bindings/python/Cargo.toml\" \"--release\" \"--lib\" \"--\" \"-C\" \"link-arg=-undefined\" \"-C\" \"link-arg=dynamic_lookup\" \"-C\" \"link-args=-Wl,-install_name,@rpath/safetensors._safetensors_rust.abi3.so\"`\n",
      "  Error: command ['maturin', 'pep517', 'build-wheel', '-i', '/Users/henry/me/proj/hang/venv/bin/python', '--compatibility', 'off'] returned non-zero exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for safetensors\u001b[0m\n",
      "Failed to build safetensors\n",
      "\u001b[31mERROR: Could not build wheels for safetensors which use PEP 517 and cannot be installed directly\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/henry/me/proj/hang/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets huggingface-hub datasets torch transformers accelerate librosa soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "187b8f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import librosa\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76b665c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoProcessor failed: Wrong index found for <|0.02|>: should be None but found 50366.\n",
      "Loading tokenizer and feature extractor separately...\n",
      "Error loading model: Wrong index found for <|0.02|>: should be None but found 50366.\n",
      "Trying with a different Whisper model...\n",
      "Fallback model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "# Load model and processor with error handling\n",
    "try:\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id, \n",
    "        torch_dtype=torch_dtype, \n",
    "        low_cpu_mem_usage=True, \n",
    "        use_safetensors=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # Try to load processor, fallback to manual tokenizer/feature_extractor if needed\n",
    "    try:\n",
    "        processor = AutoProcessor.from_pretrained(model_id)\n",
    "        tokenizer = processor.tokenizer\n",
    "        feature_extractor = processor.feature_extractor\n",
    "    except Exception as e:\n",
    "        print(f\"AutoProcessor failed: {e}\")\n",
    "        print(\"Loading tokenizer and feature extractor separately...\")\n",
    "        from transformers import WhisperTokenizer, WhisperFeatureExtractor\n",
    "        tokenizer = WhisperTokenizer.from_pretrained(model_id)\n",
    "        feature_extractor = WhisperFeatureExtractor.from_pretrained(model_id)\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        feature_extractor=feature_extractor,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    print(\"Model and pipeline loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Trying with a different Whisper model...\")\n",
    "    \n",
    "    # Fallback to a more stable model\n",
    "    model_id = \"openai/whisper-base\"\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id, \n",
    "        torch_dtype=torch_dtype, \n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device,\n",
    "    )\n",
    "    print(\"Fallback model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e056c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/henry/.cache/huggingface/datasets/distil-whisper___parquet/clean-8d6dc0c0993e781e/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de', 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
      "       0.0005188 ]), 'sampling_rate': 16000}\n",
      "Processing audio sample...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/generation/utils.py:1357: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similarly he's drawn from eating and its results occur most readily to the mind. He has graved doubts whether Sir Frederick Layton's work is really Greek after all, and can discover\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline with sample data\n",
    "try:\n",
    "    # Load a small dataset for testing\n",
    "    dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation[:1]\")\n",
    "    sample = dataset[0][\"audio\"]\n",
    "\n",
    "    print(sample)\n",
    "    \n",
    "    print(\"Processing audio sample...\")\n",
    "    result = pipe(sample)\n",
    "    print(f\"Transcription: {result['text']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing audio: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e2d724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
